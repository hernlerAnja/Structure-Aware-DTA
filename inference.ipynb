{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f70ae20",
   "metadata": {},
   "source": [
    "# Inference - run pretrained model with kiba data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9521e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "tankbind_src_folder_path = \"./tankbind/\"\n",
    "sys.path.insert(0, tankbind_src_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bffcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports from tankbind\n",
    "from feature_utils import get_protein_feature, get_clean_res_list, extract_torchdrug_feature_from_mol, get_canonical_smiles\n",
    "from utils import construct_data_from_graph_gvp, evaulate_with_affinity, evaulate\n",
    "from model import get_model\n",
    "from generation_utils import get_LAS_distance_constraint_mask, get_info_pred_distance, write_with_new_coords\n",
    "from metrics import print_metrics, myMetric\n",
    "\n",
    "# general imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from Bio.PDB import PDBParser\n",
    "import torchmetrics\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\") # NOTE: only uncomment if appearing warnings are not relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7625ac51",
   "metadata": {},
   "source": [
    "## Load molecule_dict and protein_dict & kiba_data pt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load protein and molecule dictionaries & kiba_data\n",
    "protein_dict = torch.load(\"data/protein_dict.pt\")\n",
    "molecule_dict = torch.load(\"data/molecule_dict.pt\")\n",
    "kiba_data = torch.load('data/kiba_data.pt') # NOTE: kiba_data is the complete DataFrame with the P2Rank information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5280ba22",
   "metadata": {},
   "source": [
    "# Dataset class + Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e0362e",
   "metadata": {},
   "source": [
    "I also return the target affinities together with the model input since some of the inputs might be discarded during training due to memory size issues. So I return both to keep them correctly assigned/ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46138be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset_VS(Dataset):\n",
    "    def __init__(self, root, data=None, protein_dict=None, molecule_dict=None, proteinMode=0, compoundMode=1,\n",
    "                 pocket_radius=20, shake_nodes=None,\n",
    "                 transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data = data\n",
    "        self.protein_dict = protein_dict\n",
    "        self.molecule_dict = molecule_dict\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data = torch.load(self.processed_paths[0])\n",
    "        self.protein_dict = torch.load(self.processed_paths[1])\n",
    "        self.molecule_dict = torch.load(self.processed_paths[2])\n",
    "        self.proteinMode = proteinMode\n",
    "        self.pocket_radius = pocket_radius\n",
    "        self.compoundMode = compoundMode\n",
    "        self.shake_nodes = shake_nodes\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['kiba_data.pt', 'protein_dict.pt', 'molecule_dict.pt']\n",
    "\n",
    "    def process(self):\n",
    "        # Save data and protein dictionary\n",
    "        torch.save(self.data, self.processed_paths[0])\n",
    "        torch.save(self.protein_dict, self.processed_paths[1])\n",
    "        torch.save(self.molecule_dict, self.processed_paths[2])\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        line = self.data.iloc[idx]\n",
    "        smiles = line['smiles']\n",
    "        target_affinity = line['target_affinity'] # get the target affinity value so we can return it together with the data (used for evaluation) - TODO: is it necessary, sine we have our dataframe anyway and we don't shuffle the dataset?\n",
    "        pocket_com = line['pocket_com']\n",
    "        pocket_com = np.array(pocket_com.split(\",\")).astype(float) if isinstance(pocket_com, str) else pocket_com\n",
    "        pocket_com = pocket_com.reshape((1, 3))\n",
    "        use_whole_protein = line.get('use_whole_protein', False)\n",
    "\n",
    "        protein_name = line['protein_name']\n",
    "        protein_data = self.protein_dict.get(protein_name)\n",
    "        \n",
    "        if protein_data is None:\n",
    "            raise ValueError(f\"Protein {protein_name} not found in pre-calculated protein dictionary\")\n",
    "\n",
    "        protein_node_xyz, protein_seq, protein_node_s, protein_node_v, protein_edge_index, protein_edge_s, protein_edge_v = protein_data\n",
    "\n",
    "        # Load precomputed molecular features\n",
    "        molecule_data = self.molecule_dict.get(smiles)\n",
    "        if molecule_data is None:\n",
    "            raise ValueError(f\"SMILES {smiles} not found in precomputed molecular dictionary\")\n",
    "        \n",
    "        coords, compound_node_features, input_atom_edge_list, input_atom_edge_attr_list, pair_dis_distribution = self.molecule_dict[smiles]\n",
    "\n",
    "        data, input_node_list, keepNode = construct_data_from_graph_gvp(\n",
    "            protein_node_xyz, protein_seq, protein_node_s, protein_node_v, \n",
    "            protein_edge_index, protein_edge_s, protein_edge_v,\n",
    "            coords, compound_node_features, input_atom_edge_list, input_atom_edge_attr_list,\n",
    "            pocket_radius=self.pocket_radius, use_whole_protein=use_whole_protein, includeDisMap=True,\n",
    "            use_compound_com_as_pocket=False, chosen_pocket_com=pocket_com, compoundMode=self.compoundMode\n",
    "        )\n",
    "        data.compound_pair = pair_dis_distribution.reshape(-1, 16)\n",
    "        \n",
    "        return data, target_affinity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122855a4",
   "metadata": {},
   "source": [
    "### Create dataset instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b754863",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'data' # Specify the path where the dataset will be stored\n",
    "# dataset = MyDataset_VS(root=dataset_path, data=kiba_data, protein_dict=protein_dict, molecule_dict=molecule_dict) # NOTE: use this only on first run, otherwise execute line below\n",
    "dataset = MyDataset_VS(root=dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d3f84e",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "605cbde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# check device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "140e893f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from 'c:\\\\Users\\\\anja\\\\Documents\\\\GitHub\\\\Bachelor-Thesis-AI\\\\./tankbind\\\\model.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import model\n",
    "import importlib\n",
    "\n",
    "# reload the whole module so changes in IaBNet_with_affinity and get_model are reflected\n",
    "importlib.reload(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfba7c89",
   "metadata": {},
   "source": [
    "### Masking function for bringing the vector representations to the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a226800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert z to same size vector representation \n",
    "def masked_mean_pool(z, z_mask):\n",
    "    z_mask_unsqueezed = z_mask.unsqueeze(-1)  # [B, P, C, 1]\n",
    "    masked_z = z * z_mask_unsqueezed\n",
    "    sum_z = masked_z.sum(dim=(1, 2))  # [B, H]\n",
    "    norm = z_mask_unsqueezed.sum(dim=(1, 2)) + 1e-6  # [B, 1]\n",
    "    return sum_z / norm  # [B, H]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a6ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:10:03   5 stack, readout2, pred dis map add self attention and GVP embed, compound model GIN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/11826 [00:10<35:39:49, 10.86s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10 # NOTE: max batchsize for local cpu execution\n",
    "i = 0\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "model = get_model(0, logging, device)\n",
    "\n",
    "# pretrainded self-dock model\n",
    "modelFile = \"model/self_dock.pt\"\n",
    "\n",
    "model.load_state_dict(torch.load(modelFile, map_location=device))\n",
    "_ = model.eval()\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, follow_batch=['x', 'y', 'compound_pair'], shuffle=False, num_workers=0)\n",
    "affinity_pred_list = []\n",
    "y_pred_list = [] # add code to save y_preds\n",
    "vector_representations = []\n",
    "for x, y in tqdm(data_loader):        \n",
    "    if x.dis_map.shape[0] < 100000: # remove large proteins (due to memory issues) - NOTE: adjust value to batch size and GPU memory\n",
    "        x = x.to(device) # only move x to device as y is not used in the model\n",
    "        y_pred, affinity_pred = model(x)\n",
    "\n",
    "        vector_repr = masked_mean_pool(model.vec_repr, model.z_mask) # apply the masked mean pooling to the vector representation\n",
    "\n",
    "        affinity_pred_list.append(affinity_pred.detach().cpu())\n",
    "        vector_representations.append(vector_repr.detach().cpu())\n",
    "    else:\n",
    "        affinity_pred_list.append(torch.zeros(batch_size).detach().cpu())\n",
    "        vector_representations.append(torch.zeros((batch_size, 128)).detach().cpu()) # TODO: check if 128 is the correct size for vector_repr --> should be fine (masking function reurns (batch_size, 128) vector)\n",
    "    i+=1\n",
    "    if i >= 2: break # remove this break to run over the whole dataset\n",
    "\n",
    "\n",
    "affinity_pred_list = torch.cat(affinity_pred_list)\n",
    "vector_representations = torch.cat(vector_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c96b4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affinity_pred_list shape: torch.Size([20])\n",
      "vector_representations shape: torch.Size([20, 128])\n",
      "vector_representations: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "print(f\"affinity_pred_list shape: {affinity_pred_list.shape}\")\n",
    "print(f\"vector_representations shape: {vector_representations.shape}\")\n",
    "print(f\"vector_representations[0] shape: {vector_representations[0].shape}\") # print the shape of the first vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7977a025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the affinity predictions\n",
    "torch.save(affinity_pred_list, 'data/affinity_pred.pt')\n",
    "\n",
    "# save the vector representations\n",
    "torch.save(vector_representations, 'vector_representations/vector_representations.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e728afb",
   "metadata": {},
   "source": [
    "### Add affinity predictions to kiba dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a473fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kiba_df = dataset.data\n",
    "kiba_df['affinity_pred'] = affinity_pred_list\n",
    "\n",
    "# save the updated kiba_df with affinity predictions\n",
    "kiba_df.to_csv('data/kiba_data_with_affinity_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f7ac3c",
   "metadata": {},
   "source": [
    "### Add vector representations to kiba df (if needed/possible), --> not at the moment: since labels [target_affinity] are already linked with it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cded5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check if this is needed, works like this\n",
    "# Note: currently the vector_reprs are a list with tuples of (vector_repr, target_affinity)\n",
    "\n",
    "kiba_df['vector_repr'] = vector_representations.tolist()  # Convert tensor to list for DataFrame compatibility\n",
    "# save the updated kiba_df with vector representations \n",
    "kiba_df.to_csv('vector_representations/kiba_data_with_vector_repr.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123c31b0",
   "metadata": {},
   "source": [
    "# Evaluation of the predicted affinities (needed for comparison with new model) - TODO: add concordance index metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dc252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "mse = torchmetrics.functional.mean_squared_error(kiba_df[\"affinity_pred\"].values, kiba_df['target_affinity'].values, squared=False)\n",
    "\n",
    "# mean absolute error\n",
    "mae = torchmetrics.functional.mean_absolute_error(kiba_df['affinity_pred'].values, kiba_df['target_affinity'].values)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse.item()}\")\n",
    "print(f\"Mean Absolute Error: {mae.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97b058f",
   "metadata": {},
   "source": [
    "OR (old function):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3698b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(preds, targets):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    with torch.no_grad():\n",
    "        mse = criterion(preds, targets)\n",
    "        mae = torch.mean(torch.abs(preds - targets))\n",
    "    return mse.item(), mae.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da1c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.tensor(kiba_df['affinity_pred'].to_list(), requires_grad=True, device=device)\n",
    "targets = torch.tensor(kiba_df['target_affinity'].to_list())\n",
    "\n",
    "mse, mae = eval_metrics(preds, targets)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
