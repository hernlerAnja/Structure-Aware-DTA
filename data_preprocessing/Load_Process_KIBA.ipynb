{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23cf0c57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DeepPurpose import utils, dataset\n",
    "from DeepPurpose import DTI as models\n",
    "import ast\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12118aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Processing...\n",
      "100% [............................................................................] 338300 / 338300Beginning to extract zip file...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "kiba_data = dataset.load_process_KIBA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1145b5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Processing...\n",
      "100% [............................................................................] 338300 / 338300Beginning to extract zip file...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "X_drugs, X_targets, y = dataset.load_process_KIBA() \n",
    "# X_drugs ... smiles representation of drugs\n",
    "# X_targets ... amino acid sequence of protein targets\n",
    "# y ... binding affinity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95187f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES Array: (118254,)\n",
      "Protein Sequences Array: (118254,)\n",
      "Affinity Scores Array: (118254,)\n"
     ]
    }
   ],
   "source": [
    "print(\"SMILES Array:\", X_drugs.shape)\n",
    "print(\"Protein Sequences Array:\", X_targets.shape)\n",
    "print(\"Affinity Scores Array:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9206ad",
   "metadata": {},
   "source": [
    "### Map Uniprot ID to drug sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0f57f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mapping file\n",
    "file = ast.literal_eval(open('proteins.txt', 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5be572e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for kiba_data\n",
    "kiba_data = np.stack((X_drugs, X_targets, y), axis=-1) # Shape = (118254, 3)\n",
    "\n",
    "# map uniprot ids to sequences\n",
    "result = []\n",
    "for row in kiba_data:\n",
    "    value = row[1]\n",
    "    key = list(filter(lambda x: file[x] == value, file))[0] \n",
    "    new_row = np.append(row, key)\n",
    "    result.append(new_row)\n",
    "result = np.array(result)\n",
    "\n",
    "kiba_data_df = pd.DataFrame(result, columns=['Smiles', 'molecules', 'target_affinity', 'uniprot_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c3d0d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>molecules</th>\n",
       "      <th>target_affinity</th>\n",
       "      <th>uniprot_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>MTVKTEAAKGTLTYSRMRGMVAILIAFMKQRRMGLNDFIQKIANNS...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>O00141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>MSWSPSLTTQTCGAWEMKERLGTGGFGNVIRWHNQETGEQIAIKQC...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>O14920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>MERPPGLRPGAGGPWEMRERLGTGGFGNVCLYQHRELDLKIAIKSC...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>O15111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>MRPSGTAGAALLALLAALCPASRALEEKKVCQGTSNKLTQLGTFED...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>P00533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>MELAALCRWGLLLALLPPGAASTQVCTGTDMKLRLPASPETHLDML...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>P04626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Smiles   \n",
       "0  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl  \\\n",
       "1  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
       "2  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
       "3  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
       "4  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
       "\n",
       "                                           molecules target_affinity   \n",
       "0  MTVKTEAAKGTLTYSRMRGMVAILIAFMKQRRMGLNDFIQKIANNS...            11.1  \\\n",
       "1  MSWSPSLTTQTCGAWEMKERLGTGGFGNVIRWHNQETGEQIAIKQC...            11.1   \n",
       "2  MERPPGLRPGAGGPWEMRERLGTGGFGNVCLYQHRELDLKIAIKSC...            11.1   \n",
       "3  MRPSGTAGAALLALLAALCPASRALEEKKVCQGTSNKLTQLGTFED...            11.1   \n",
       "4  MELAALCRWGLLLALLPPGAASTQVCTGTDMKLRLPASPETHLDML...            11.1   \n",
       "\n",
       "  uniprot_id  \n",
       "0     O00141  \n",
       "1     O14920  \n",
       "2     O15111  \n",
       "3     P00533  \n",
       "4     P04626  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiba_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8920c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df if needed\n",
    "kiba_data_df.to_csv('kiba_data_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fd1e80",
   "metadata": {},
   "source": [
    "### Map Uniprot ID to Pdb ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc76b869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 195 Uniprot to PDB mappings.\n"
     ]
    }
   ],
   "source": [
    "# load mapping file\n",
    "def load_mappings(file):\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    mappings = {}\n",
    "    \n",
    "    # Iterate over the results and add the first occurrence of each Uniprot ID\n",
    "    for entry in data['results']:\n",
    "        uniprot_id = entry['from']\n",
    "        pdb_id = entry['to']\n",
    "        \n",
    "        if uniprot_id not in mappings: # Only add the first occurence\n",
    "            mappings[uniprot_id] = pdb_id\n",
    "        \n",
    "    return mappings\n",
    "\n",
    "mappings = load_mappings('idmapping_2023_11_12.json')\n",
    "print(f\"Loaded {len(mappings)} Uniprot to PDB mappings.\") \n",
    "# dict structure: {'results': [{'from': 'O00141', 'to': '2R5T'}, {...}, ...]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9462554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map uniprot to pdb id\n",
    "def map_uniprot_to_pdb(df, mappings):\n",
    "    df['pdb_id'] = df['uniprot_id'].map(mappings)\n",
    "    return df\n",
    "\n",
    "# Add pdb ids to Kiba df\n",
    "kiba_data_df_with_ids = map_uniprot_to_pdb(kiba_data_df, mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eb80390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>molecules</th>\n",
       "      <th>target_affinity</th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>pdb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>MTVKTEAAKGTLTYSRMRGMVAILIAFMKQRRMGLNDFIQKIANNS...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>O00141</td>\n",
       "      <td>2R5T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>MSWSPSLTTQTCGAWEMKERLGTGGFGNVIRWHNQETGEQIAIKQC...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>O14920</td>\n",
       "      <td>3BRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>MERPPGLRPGAGGPWEMRERLGTGGFGNVCLYQHRELDLKIAIKSC...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>O15111</td>\n",
       "      <td>3BRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>MRPSGTAGAALLALLAALCPASRALEEKKVCQGTSNKLTQLGTFED...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>P00533</td>\n",
       "      <td>1IVO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>MELAALCRWGLLLALLPPGAASTQVCTGTDMKLRLPASPETHLDML...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>P04626</td>\n",
       "      <td>1MFG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Smiles   \n",
       "0  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl  \\\n",
       "1  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
       "2  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
       "3  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
       "4  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
       "\n",
       "                                           molecules target_affinity   \n",
       "0  MTVKTEAAKGTLTYSRMRGMVAILIAFMKQRRMGLNDFIQKIANNS...            11.1  \\\n",
       "1  MSWSPSLTTQTCGAWEMKERLGTGGFGNVIRWHNQETGEQIAIKQC...            11.1   \n",
       "2  MERPPGLRPGAGGPWEMRERLGTGGFGNVCLYQHRELDLKIAIKSC...            11.1   \n",
       "3  MRPSGTAGAALLALLAALCPASRALEEKKVCQGTSNKLTQLGTFED...            11.1   \n",
       "4  MELAALCRWGLLLALLPPGAASTQVCTGTDMKLRLPASPETHLDML...            11.1   \n",
       "\n",
       "  uniprot_id pdb_id  \n",
       "0     O00141   2R5T  \n",
       "1     O14920   3BRT  \n",
       "2     O15111   3BRT  \n",
       "3     P00533   1IVO  \n",
       "4     P04626   1MFG  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiba_data_df_with_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63829102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN values found in 'pdb_id' column.\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any NaN values in the 'pdb_id' column\n",
    "nan_pdb_ids = kiba_data_df_with_ids[kiba_data_df_with_ids['pdb_id'].isna()]\n",
    "\n",
    "if not nan_pdb_ids.empty:\n",
    "    print(f\"Rows with NaN pdb_id:{len(nan_pdb_ids)}\")\n",
    "else:\n",
    "    print(\"No NaN values found in 'pdb_id' column.\")\n",
    "\n",
    "# for simplicity we replace the nan values in the pdb_id col with the correspoding uniprot_ids\n",
    "kiba_data_df_with_ids['pdb_id'] = kiba_data_df_with_ids['pdb_id'].fillna(kiba_data_df_with_ids['uniprot_id'])\n",
    "# Now, the rows that had NaN in the 'pdb_id' column will have the corresponding 'uniprot_id' in their place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91743690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df if needed\n",
    "kiba_data_df_with_ids.to_csv('kiba_data_df_with_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a229267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY EXECUTE IF YOU WANT TO REMOVE THE ROWS\n",
    "# Remove rows where the 'pdb_id' column has NaN values\n",
    "# kiba_data_clean = kiba_data_with_pdb.dropna(subset=['pdb_id'])\n",
    "# Check how many rows were removed\n",
    "# print(f\"Rows remaining after dropping NaN pdb_ids: {len(kiba_data_clean)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2862a0",
   "metadata": {},
   "source": [
    "### Download the PDB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b5017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n"
     ]
    }
   ],
   "source": [
    "# download PDB from PDB or AlphaFold based on availability\n",
    "def download_pdb(pdb_id, download_dir):\n",
    "    # Check if the PDB file already exists\n",
    "    exists = 0\n",
    "    pdb_file_path = os.path.join(download_dir, f\"{pdb_id}.pdb\")\n",
    "    if os.path.exists(pdb_file_path):\n",
    "        #print(f\"File for {pdb_id} already exists.\")\n",
    "        exists += 1\n",
    "        return pdb_file_path, exists\n",
    "\n",
    "    # Try downloading from PDB database first\n",
    "    pdb_url = f'https://files.rcsb.org/download/{pdb_id}.pdb'\n",
    "    response = requests.get(pdb_url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Save PDB file to local directory\n",
    "        with open(pdb_file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded {pdb_id} from PDB.\")\n",
    "    else:\n",
    "        # If not found in PDB, try AlphaFold (use alternative base URL)\n",
    "        alphafold_url = f'https://alphafold.ebi.ac.uk/files/AF-{pdb_id}-F1-model_v2.pdb'\n",
    "        response = requests.get(alphafold_url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            # Save PDB file from AlphaFold\n",
    "            with open(pdb_file_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Downloaded {pdb_id} from AlphaFold.\")\n",
    "        else:\n",
    "            print(f\"Failed to download {pdb_id}. Neither PDB nor AlphaFold has the file.\")\n",
    "            return None\n",
    "\n",
    "    return pdb_file_path\n",
    "\n",
    "# Create a directory to save the downloaded PDB files\n",
    "download_dir = \"PDB_files\"\n",
    "# download_dir = \"../PDB_files\" # new file path (TODO: check if it works)\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "\n",
    "# Get unique pdb_ids (including missing ones from NaN)\n",
    "unique_pdb_ids = kiba_data_df_with_ids['pdb_id'].dropna().unique() # 226\n",
    "\n",
    "# Download each PDB file (only once)\n",
    "counter = 0\n",
    "for pdb_id in unique_pdb_ids:\n",
    "    p, e = download_pdb(pdb_id, download_dir)\n",
    "    if e == 1:\n",
    "        counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818cab71-291a-47b0-bd3f-84625592ae4e",
   "metadata": {},
   "source": [
    "## get protein features (protein_dict) for p2rank selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830f1b3c-3130-49ae-81d6-8f0e6bf50191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Load the dictionary from the file\n",
    "protein_dict = torch.load(\"protein_dict.pt\")\n",
    "# protein_dict = torch.load(\"../data/protein_dict.pt\") # new file path (TODO: check if it works)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33068e04-18fe-4fb1-ad7f-9925ec89682f",
   "metadata": {},
   "source": [
    "## create dataset.ds for p2rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d08576d-cdb0-4de3-b6a0-a9df5bffbcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File paths written to protein_list.ds\n"
     ]
    }
   ],
   "source": [
    "######################################## ONL EXECURE ONCE!!! ###########################################\n",
    "# Directory containing your PDB files\n",
    "pdb_directory = 'PDB_files'\n",
    "# pdb_directory = \"../PDB_files\" # new file path (TODO: check if it works)\n",
    "\n",
    "# Output file name for the .ds file\n",
    "ds_file = \"protein_list.ds\"\n",
    "\n",
    "# List all .pdb files in the directory\n",
    "pdb_files = [file for file in os.listdir(pdb_directory) if file.endswith(\".pdb\")]\n",
    "\n",
    "# Write the file paths to the .ds file\n",
    "with open(ds_file, \"w\") as f:\n",
    "    for pdb_file in pdb_files:\n",
    "        f.write(os.path.join(pdb_directory, pdb_file) + \"\\n\")\n",
    "\n",
    "print(\"File paths written to\", ds_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8449ce9",
   "metadata": {},
   "source": [
    "# p2rank for protein segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d00c4517-1487-4b30-9a0a-835e83a4b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from Bio.PDB import PDBParser\n",
    "import torchmetrics\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55d0b7f-ec91-45da-9999-45afb341a4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Smiles</th>\n",
       "      <th>molecules</th>\n",
       "      <th>target_affinity</th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>pdb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>MTVKTEAAKGTLTYSRMRGMVAILIAFMKQRRMGLNDFIQKIANNS...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>O00141</td>\n",
       "      <td>2R5T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>MSWSPSLTTQTCGAWEMKERLGTGGFGNVIRWHNQETGEQIAIKQC...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>O14920</td>\n",
       "      <td>3BRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>MERPPGLRPGAGGPWEMRERLGTGGFGNVCLYQHRELDLKIAIKSC...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>O15111</td>\n",
       "      <td>3BRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>MRPSGTAGAALLALLAALCPASRALEEKKVCQGTSNKLTQLGTFED...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>P00533</td>\n",
       "      <td>1IVO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>MELAALCRWGLLLALLPPGAASTQVCTGTDMKLRLPASPETHLDML...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>P04626</td>\n",
       "      <td>1MFG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         Smiles  \\\n",
       "0           0  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
       "1           1  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
       "2           2  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
       "3           3  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
       "4           4  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
       "\n",
       "                                           molecules  target_affinity  \\\n",
       "0  MTVKTEAAKGTLTYSRMRGMVAILIAFMKQRRMGLNDFIQKIANNS...             11.1   \n",
       "1  MSWSPSLTTQTCGAWEMKERLGTGGFGNVIRWHNQETGEQIAIKQC...             11.1   \n",
       "2  MERPPGLRPGAGGPWEMRERLGTGGFGNVCLYQHRELDLKIAIKSC...             11.1   \n",
       "3  MRPSGTAGAALLALLAALCPASRALEEKKVCQGTSNKLTQLGTFED...             11.1   \n",
       "4  MELAALCRWGLLLALLPPGAASTQVCTGTDMKLRLPASPETHLDML...             11.1   \n",
       "\n",
       "  uniprot_id pdb_id  \n",
       "0     O00141   2R5T  \n",
       "1     O14920   3BRT  \n",
       "2     O15111   3BRT  \n",
       "3     P00533   1IVO  \n",
       "4     P04626   1MFG  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load df\n",
    "kiba_data_df_with_ids = pd.read_csv('kiba_data_df_with_ids.csv')\n",
    "kiba_data_df_with_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f64ee-8d8a-4d8b-8ab5-c83543ca6ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 118254/118254 [03:49<00:00, 515.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  protein_name compound_name                                         smiles  \\\n",
      "0         2R5T                COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
      "1         3BRT                COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
      "2         3BRT                COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
      "3         1IVO                COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
      "4         1MFG                COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
      "\n",
      "          pocket_name             pocket_com  target_affinity  \n",
      "0  best_p2rank_pocket    32.53,34.506,67.174             11.1  \n",
      "1  best_p2rank_pocket   14.396,20.696,11.566             11.1  \n",
      "2  best_p2rank_pocket   14.396,20.696,11.566             11.1  \n",
      "3  best_p2rank_pocket  115.598,69.377,45.458             11.1  \n",
      "4  best_p2rank_pocket     8.068,0.821,17.188             11.1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to process proteins with P2Rank --> do externally via bash console\n",
    "# run via bash console due to path issues with P2Rank\n",
    "\n",
    "#def run_p2rank_for_protein(protein_name, ds='protein_list.ds'):\n",
    "    # P2Rank command\n",
    " ##   p2rank = \"/c/Users/anja/OneDrive/Dokumente/GitHub/Practical-Work-for-AI/p2rank/prank.sh\"\n",
    "   # output_dir = \"p2rank_files\"\n",
    "    \n",
    "    \n",
    "    #cmd = f\"bash {p2rank} predict {ds} -o {output_dir} -threads 1\"\n",
    "    #os.system(cmd)\n",
    "\n",
    "# Store the information in a list to be turned into a DataFrame\n",
    "info = []\n",
    "\n",
    "# Process each row in the dataframe\n",
    "for i, line in tqdm(kiba_data_df_with_ids.iterrows(), total=kiba_data_df_with_ids.shape[0]):\n",
    "    smiles = line['Smiles']\n",
    "    compound_name = \"\"\n",
    "    protein_name = line['pdb_id']\n",
    "    affinity = line['target_affinity']  # Adjust this if your affinity column has a different name\n",
    "\n",
    "    # Check for P2Rank prediction file\n",
    "    p2rank_file = f\"p2rank_files/{protein_name}.pdb_predictions.csv\"\n",
    "    # p2rank_file = f\"../p2rank_files/{protein_name}.pdb_predictions.csv\"  # new file path (TODO: check if it works)\n",
    "    \n",
    "    # Skip running P2Rank if prediction already exists only needed if p2rank is run in notebook per protein but since we run it externally, we can skip this\n",
    "    # if not os.path.exists(p2rank_file):\n",
    "       # run_p2rank_for_protein(protein_name)\n",
    "    \n",
    "    if os.path.exists(p2rank_file):\n",
    "        pocket = pd.read_csv(p2rank_file, sep=',')\n",
    "        pocket.columns = pocket.columns.str.strip()  # Clean column names\n",
    "\n",
    "        if not pocket.empty:\n",
    "            # Use the best pocket (rank 1, which should be the first row)\n",
    "            best_pocket = pocket.iloc[0]\n",
    "            com = \",\".join([str(round(best_pocket[c], 3)) for c in ['center_x', 'center_y', 'center_z']])\n",
    "            info.append([protein_name, compound_name, smiles, \"best_p2rank_pocket\", com, affinity])\n",
    "        else:\n",
    "            # Fallback: use protein center as the pocket center\n",
    "            com = \",\".join([str(a.round(3)) for a in protein_dict[protein_name][0].mean(axis=0).numpy()])\n",
    "            info.append([protein_name, compound_name, smiles, \"protein_center\", com, affinity])\n",
    "    else:\n",
    "        # Fallback: use protein center as the pocket center\n",
    "        com = \",\".join([str(a.round(3)) for a in protein_dict[protein_name][0].mean(axis=0).numpy()])\n",
    "        info.append([protein_name, compound_name, smiles, \"protein_center\", com, affinity])\n",
    "\n",
    "\n",
    "# Convert the list of information into a DataFrame\n",
    "info_df = pd.DataFrame(info, columns=[\n",
    "    'protein_name', 'compound_name', 'smiles', 'pocket_name', 'pocket_com', 'target_affinity'\n",
    "])\n",
    "\n",
    "# Check the result\n",
    "print(info_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9795b180-726a-4083-935f-af454590d9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_name</th>\n",
       "      <th>compound_name</th>\n",
       "      <th>smiles</th>\n",
       "      <th>pocket_name</th>\n",
       "      <th>pocket_com</th>\n",
       "      <th>target_affinity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2R5T</td>\n",
       "      <td></td>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>best_p2rank_pocket</td>\n",
       "      <td>32.53,34.506,67.174</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3BRT</td>\n",
       "      <td></td>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>best_p2rank_pocket</td>\n",
       "      <td>14.396,20.696,11.566</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3BRT</td>\n",
       "      <td></td>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>best_p2rank_pocket</td>\n",
       "      <td>14.396,20.696,11.566</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1IVO</td>\n",
       "      <td></td>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>best_p2rank_pocket</td>\n",
       "      <td>115.598,69.377,45.458</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1MFG</td>\n",
       "      <td></td>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>best_p2rank_pocket</td>\n",
       "      <td>8.068,0.821,17.188</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protein_name compound_name                                         smiles  \\\n",
       "0         2R5T                COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
       "1         3BRT                COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
       "2         3BRT                COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
       "3         1IVO                COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
       "4         1MFG                COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
       "\n",
       "          pocket_name             pocket_com  target_affinity  \n",
       "0  best_p2rank_pocket    32.53,34.506,67.174             11.1  \n",
       "1  best_p2rank_pocket   14.396,20.696,11.566             11.1  \n",
       "2  best_p2rank_pocket   14.396,20.696,11.566             11.1  \n",
       "3  best_p2rank_pocket  115.598,69.377,45.458             11.1  \n",
       "4  best_p2rank_pocket     8.068,0.821,17.188             11.1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68900a33-f8b6-424c-8614-95f87a39972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df.to_csv('kiba_data_with_p2rank_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e6cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save kiba_data with p2rank info as pt file\n",
    "kiba_data = pd.read_csv('kiba_data_with_p2rank_info.csv')\n",
    "torch.save(kiba_data, 'kiba_data.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226f3c08",
   "metadata": {},
   "source": [
    "# !!!!Stop here and continue in new notebook for dataset creation!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b119295",
   "metadata": {},
   "source": [
    "## Load molecule_dict and protein_dict & kiba_data pt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c8acbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load protein and molecule dictionaries & kiba_data\n",
    "protein_dict = torch.load(\"protein_dict.pt\")\n",
    "molecule_dict = torch.load(\"molecule_dict.pt\")\n",
    "kiba_data = torch.load('kiba_data.pt') # kiba_data is the complete DataFrame with the P2Rank information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d77a92",
   "metadata": {},
   "source": [
    "# Dataset class + Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911967b2",
   "metadata": {},
   "source": [
    "I also return the target affinities together with the model input since some of the inputs might be discarded during training due to memory size issues. So I return both to keep them correctly assigned/ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5efa83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tankbind_src_folder_path = \"./tankbind/\"\n",
    "sys.path.insert(0, tankbind_src_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4adfb505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports from tankbind\n",
    "from feature_utils import get_protein_feature, get_clean_res_list, extract_torchdrug_feature_from_mol, get_canonical_smiles\n",
    "from utils import construct_data_from_graph_gvp, evaulate_with_affinity, evaulate\n",
    "from model import get_model\n",
    "from generation_utils import get_LAS_distance_constraint_mask, get_info_pred_distance, write_with_new_coords\n",
    "from metrics import print_metrics, myMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963e52e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset_VS(Dataset):\n",
    "    def __init__(self, root, data=None, protein_dict=None, molecule_dict=None, proteinMode=0, compoundMode=1,\n",
    "                 pocket_radius=20, shake_nodes=None,\n",
    "                 transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data = data\n",
    "        self.protein_dict = protein_dict\n",
    "        self.molecule_dict = molecule_dict\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data = torch.load(self.processed_paths[0])\n",
    "        self.protein_dict = torch.load(self.processed_paths[1])\n",
    "        self.molecule_dict = torch.load(self.processed_paths[2])\n",
    "        self.proteinMode = proteinMode\n",
    "        self.pocket_radius = pocket_radius\n",
    "        self.compoundMode = compoundMode\n",
    "        self.shake_nodes = shake_nodes\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['kiba_data.pt', 'protein_dict.pt', 'molecule_dict.pt']\n",
    "\n",
    "    def process(self):\n",
    "        # Save data and protein dictionary\n",
    "        torch.save(self.data, self.processed_paths[0])\n",
    "        torch.save(self.protein_dict, self.processed_paths[1])\n",
    "        torch.save(self.molecule_dict, self.processed_paths[2])\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        line = self.data.iloc[idx]\n",
    "        smiles = line['smiles']\n",
    "        target_affinity = line['target_affinity']\n",
    "        pocket_com = line['pocket_com']\n",
    "        pocket_com = np.array(pocket_com.split(\",\")).astype(float) if isinstance(pocket_com, str) else pocket_com\n",
    "        pocket_com = pocket_com.reshape((1, 3))\n",
    "        use_whole_protein = line.get('use_whole_protein', False)\n",
    "\n",
    "        protein_name = line['protein_name']\n",
    "        protein_data = self.protein_dict.get(protein_name)\n",
    "        \n",
    "        if protein_data is None:\n",
    "            raise ValueError(f\"Protein {protein_name} not found in pre-calculated protein dictionary\")\n",
    "\n",
    "        protein_node_xyz, protein_seq, protein_node_s, protein_node_v, protein_edge_index, protein_edge_s, protein_edge_v = protein_data\n",
    "\n",
    "        # Load precomputed molecular features\n",
    "        molecule_data = self.molecule_dict.get(smiles)\n",
    "        if molecule_data is None:\n",
    "            raise ValueError(f\"SMILES {smiles} not found in precomputed molecular dictionary\")\n",
    "        \n",
    "        coords, compound_node_features, input_atom_edge_list, input_atom_edge_attr_list, pair_dis_distribution = self.molecule_dict[smiles]\n",
    "\n",
    "        data, input_node_list, keepNode = construct_data_from_graph_gvp(\n",
    "            protein_node_xyz, protein_seq, protein_node_s, protein_node_v, \n",
    "            protein_edge_index, protein_edge_s, protein_edge_v,\n",
    "            coords, compound_node_features, input_atom_edge_list, input_atom_edge_attr_list,\n",
    "            pocket_radius=self.pocket_radius, use_whole_protein=use_whole_protein, includeDisMap=True,\n",
    "            use_compound_com_as_pocket=False, chosen_pocket_com=pocket_com, compoundMode=self.compoundMode\n",
    "        )\n",
    "        data.compound_pair = pair_dis_distribution.reshape(-1, 16)\n",
    "        \n",
    "        return data, target_affinity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bd59cc",
   "metadata": {},
   "source": [
    "### create dataset instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f0eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '' # Specify the path where the dataset will be stored (TODO: some directory cleanup)\n",
    "# dataset = MyDataset_VS(root=dataset_path, data=kiba_data, protein_dict=protein_dict, molecule_dict=molecule_dict) # only on first run, otherwise execute line below\n",
    "# dataset = MyDataset_VS(root=dataset_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
