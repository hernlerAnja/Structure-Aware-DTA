{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f70ae20",
   "metadata": {},
   "source": [
    "# Inference - run pretrained model with kiba data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9521e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "tankbind_src_folder_path = \"./tankbind/\"\n",
    "sys.path.insert(0, tankbind_src_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bffcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports from tankbind\n",
    "from feature_utils import get_protein_feature, get_clean_res_list, extract_torchdrug_feature_from_mol, get_canonical_smiles\n",
    "from utils import construct_data_from_graph_gvp, evaulate_with_affinity, evaulate\n",
    "from model import get_model\n",
    "from generation_utils import get_LAS_distance_constraint_mask, get_info_pred_distance, write_with_new_coords\n",
    "from metrics import print_metrics, myMetric\n",
    "\n",
    "# general imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from Bio.PDB import PDBParser\n",
    "import torchmetrics\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\") # only uncomment if appearing warnings are not relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7625ac51",
   "metadata": {},
   "source": [
    "## Load molecule_dict and protein_dict & kiba_data pt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load protein and molecule dictionaries & kiba_data\n",
    "protein_dict = torch.load(\"data/protein_dict.pt\")\n",
    "molecule_dict = torch.load(\"data/molecule_dict.pt\")\n",
    "kiba_data = torch.load('data/kiba_data.pt') # kiba_data is the complete DataFrame with the P2Rank information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5280ba22",
   "metadata": {},
   "source": [
    "# Dataset class + Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e0362e",
   "metadata": {},
   "source": [
    "I also return the target affinities together with the model input since some of the inputs might be discarded during training due to memory size issues. So I return both to keep them correctly assigned/ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46138be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset_VS(Dataset):\n",
    "    def __init__(self, root, data=None, protein_dict=None, molecule_dict=None, proteinMode=0, compoundMode=1,\n",
    "                 pocket_radius=20, shake_nodes=None,\n",
    "                 transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data = data\n",
    "        self.protein_dict = protein_dict\n",
    "        self.molecule_dict = molecule_dict\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data = torch.load(self.processed_paths[0])\n",
    "        self.protein_dict = torch.load(self.processed_paths[1])\n",
    "        self.molecule_dict = torch.load(self.processed_paths[2])\n",
    "        self.proteinMode = proteinMode\n",
    "        self.pocket_radius = pocket_radius\n",
    "        self.compoundMode = compoundMode\n",
    "        self.shake_nodes = shake_nodes\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['kiba_data.pt', 'protein_dict.pt', 'molecule_dict.pt']\n",
    "\n",
    "    def process(self):\n",
    "        # Save data and protein dictionary\n",
    "        torch.save(self.data, self.processed_paths[0])\n",
    "        torch.save(self.protein_dict, self.processed_paths[1])\n",
    "        torch.save(self.molecule_dict, self.processed_paths[2])\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        line = self.data.iloc[idx]\n",
    "        smiles = line['smiles']\n",
    "        target_affinity = line['target_affinity']\n",
    "        pocket_com = line['pocket_com']\n",
    "        pocket_com = np.array(pocket_com.split(\",\")).astype(float) if isinstance(pocket_com, str) else pocket_com\n",
    "        pocket_com = pocket_com.reshape((1, 3))\n",
    "        use_whole_protein = line.get('use_whole_protein', False)\n",
    "\n",
    "        protein_name = line['protein_name']\n",
    "        protein_data = self.protein_dict.get(protein_name)\n",
    "        \n",
    "        if protein_data is None:\n",
    "            raise ValueError(f\"Protein {protein_name} not found in pre-calculated protein dictionary\")\n",
    "\n",
    "        protein_node_xyz, protein_seq, protein_node_s, protein_node_v, protein_edge_index, protein_edge_s, protein_edge_v = protein_data\n",
    "\n",
    "        # Load precomputed molecular features\n",
    "        molecule_data = self.molecule_dict.get(smiles)\n",
    "        if molecule_data is None:\n",
    "            raise ValueError(f\"SMILES {smiles} not found in precomputed molecular dictionary\")\n",
    "        \n",
    "        coords, compound_node_features, input_atom_edge_list, input_atom_edge_attr_list, pair_dis_distribution = self.molecule_dict[smiles]\n",
    "\n",
    "        data, input_node_list, keepNode = construct_data_from_graph_gvp(\n",
    "            protein_node_xyz, protein_seq, protein_node_s, protein_node_v, \n",
    "            protein_edge_index, protein_edge_s, protein_edge_v,\n",
    "            coords, compound_node_features, input_atom_edge_list, input_atom_edge_attr_list,\n",
    "            pocket_radius=self.pocket_radius, use_whole_protein=use_whole_protein, includeDisMap=True,\n",
    "            use_compound_com_as_pocket=False, chosen_pocket_com=pocket_com, compoundMode=self.compoundMode\n",
    "        )\n",
    "        data.compound_pair = pair_dis_distribution.reshape(-1, 16)\n",
    "        \n",
    "        return data, target_affinity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122855a4",
   "metadata": {},
   "source": [
    "### Create dataset instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b754863",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'data/dataset' # Specify the path where the dataset will be stored (TODO: some directory cleanup)\n",
    "dataset = MyDataset_VS(root=dataset_path, data=kiba_data, protein_dict=protein_dict, molecule_dict=molecule_dict) # only on first run, otherwise execute line below\n",
    "# dataset = MyDataset_VS(root=dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d3f84e",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605cbde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a6ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "model = get_model(0, logging, device)\n",
    "\n",
    "# self-dock model\n",
    "modelFile = \"/system/user/studentwork/hernler/tankbind_project_data/self_dock.pt\"\n",
    "\n",
    "model.load_state_dict(torch.load(modelFile, map_location=device))\n",
    "_ = model.eval()\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, follow_batch=['x', 'y', 'compound_pair'], shuffle=False, num_workers=0)\n",
    "affinity_pred_list = []\n",
    "y_pred_list = [] # add code to save y_preds\n",
    "vector_representations = []\n",
    "for x, y in tqdm(data_loader):        \n",
    "    if x.dis_map.shape[0] < 20000:\n",
    "        x = x.to(device) # only move x to device as y is not used in the model\n",
    "        y_pred, affinity_pred, vector_repr = model(x)\n",
    "        affinity_pred_list.append(affinity_pred.detach().cpu())\n",
    "        vector_representations.append((vector_repr.detach().cpu(), y))\n",
    "    else:\n",
    "        affinity_pred_list.append(torch.zeros(batch_size).detach().cpu())\n",
    "        vector_representations.append((torch.zeros((batch_size, 128)).detach().cpu(), y)) # TODO: check if 128 is the correct size for vector_repr\n",
    "\n",
    "\n",
    "affinity_pred_list = torch.cat(affinity_pred_list)\n",
    "vector_representations = torch.stack([v[0] for v in vector_representations]) # TODO: check if this is correct / if it is needed to also add target affinities, since the list bshould hae the same length as the data_loader/dataset(kiba_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7977a025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the affinity predictions\n",
    "torch.save(affinity_pred_list, 'data/affinity_pred.pt')\n",
    "\n",
    "# save the vector representations\n",
    "torch.save(vector_representations, 'vector_representations/vector_representations.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e728afb",
   "metadata": {},
   "source": [
    "### Add affinity predictions to kiba dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a473fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kiba_df = dataset.data\n",
    "kiba_df['affinity_pred'] = affinity_pred_list\n",
    "\n",
    "# save the updated kiba_df with affinity predictions\n",
    "kiba_df.to_csv('data/kiba_data_with_affinity_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f7ac3c",
   "metadata": {},
   "source": [
    "### Add vector representations to kiba df (if needed, since labels [target_affinity] are already linked with it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cded5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check if this is needed, works like this\n",
    "# Note: currently the vector_reprs are a list with tuples of (vector_repr, target_affinity)\n",
    "\n",
    "kiba_df['vector_repr'] = vector_representations.tolist()  # Convert tensor to list for DataFrame compatibility\n",
    "# save the updated kiba_df with vector representations \n",
    "kiba_df.to_csv('vector_representations/kiba_data_with_vector_repr.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123c31b0",
   "metadata": {},
   "source": [
    "# Evaluation of the predicted affinities (needed for comparison with new model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dc252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "mse = torchmetrics.functional.mean_squared_error(kiba_df[\"affinity_pred\"].values, kiba_df['target_affinity'].values, squared=False)\n",
    "\n",
    "# mean absolute error\n",
    "mae = torchmetrics.functional.mean_absolute_error(kiba_df['affinity_pred'].values, kiba_df['target_affinity'].values)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse.item()}\")\n",
    "print(f\"Mean Absolute Error: {mae.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97b058f",
   "metadata": {},
   "source": [
    "OR (old function):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3698b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(preds, targets):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    with torch.no_grad():\n",
    "        mse = criterion(preds, targets)\n",
    "        mae = torch.mean(torch.abs(preds - targets))\n",
    "    return mse.item(), mae.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da1c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.tensor(kiba_df['affinity_pred'].to_list(), requires_grad=True, device=device)\n",
    "targets = torch.tensor(kiba_df['target_affinity'].to_list())\n",
    "\n",
    "mse, mae = eval_metrics(preds, targets)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
